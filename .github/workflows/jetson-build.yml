name: Build Jetson Orin Nano Disk Image

on:
  release:
    types: [published]
  push:
    # branches: [ main, master, selfhosted, Build-RootFS-from-Ubuntu-Base ]
    tags: [ 'v*' ]
  # pull_request:
  #   branches: [ main, master ]
  workflow_dispatch:
    inputs:
      l4t_major_version:
        description: 'L4T Version (default: 36)'
        required: false
        default: '36'
      l4t_minor_version:
        description: 'L4T Version (default: 4.4)'
        required: false
        default: '4.4'
      image_type:
        description: 'Output image drive type (SD/USB/NVME)'
        required: false
        default: 'NVME'
      jetson_type:
        description: 'Jetson board type'
        required: false
        default: 'jetson-orin-nano-devkit-super'

# permissions:
#   contents: read

env:
  L4T_MAJOR_VERSION: "${{ github.event.env.L4T_MAJOR_VERSION || '36' }}"
  L4T_MINOR_VERSION: "${{ github.event.env.L4T_MINOR_VERSION || '4.4' }}"
  IMAGE_TYPE: "${{ github.event.inputs.image_type || 'NVME' }}"
  JETSON_TYPE: "${{ github.event.inputs.jetson_type || 'jetson-orin-nano-devkit-super' }}"
  OEM_USER: "nexus"

jobs:
  cache-jetson-downloads:
    # runs-on: self-hosted
    runs-on: ubuntu-22.04

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Cache L4T BSP and Sample Root FS
      id: cache-bsp
      uses: actions/cache@v4
      with:
        path: ${{ github.workspace }}/Linux_for_Tegra.tar.zst
        key: bsp-${{ env.L4T_MAJOR_VERSION }}.${{ env.L4T_MINOR_VERSION }}
        lookup-only: true

    - name: Download and extract L4T Driver Package & Sample Root filesystem
      if: steps.cache-bsp.outputs.cache-hit != 'true'
      run: |
        echo "Downloading L4T Driver Package (BSP)..."
        wget -q -O Jetson_Linux_aarch64.tbz2 https://developer.nvidia.com/downloads/embedded/l4t/r${{ env.L4T_MAJOR_VERSION }}_release_v${{ env.L4T_MINOR_VERSION }}/release/Jetson_Linux_r${{ env.L4T_MAJOR_VERSION }}.${{ env.L4T_MINOR_VERSION }}_aarch64.tbz2
        echo "Extracting L4T Driver Package (BSP)..."
        tar -xjf Jetson_Linux_aarch64.tbz2 -C $GITHUB_WORKSPACE/
        echo "Compress L4T..."
        sudo tar --create --preserve-permissions --use-compress-program=zstd -f $GITHUB_WORKSPACE/Linux_for_Tegra.tar.zst -C $GITHUB_WORKSPACE Linux_for_Tegra

  create-draft:
    # runs-on: self-hosted
    runs-on: ubuntu-latest
    outputs:
      upload_url: ${{ steps.create_release.outputs.upload_url }}
      release_id: ${{ steps.create_release.outputs.id }}
    steps:
      - name: Create draft
        if: startsWith(github.ref, 'refs/tags/')
        id: create_release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ github.ref_name }}
          name: Release ${{ github.ref_name }}
          draft: true
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  build-jetson-image:
    # runs-on: self-hosted
    runs-on: ubuntu-22.04
    needs: [cache-jetson-downloads, create-draft]

    steps:
    # - name: Disable man-db to make package install and removal faster
    #   run: |
    #     echo 'set man-db/auto-update false' | sudo debconf-communicate >/dev/null
    #     sudo dpkg-reconfigure man-db

    # - name: Free Disk Space
    #   # uses: jlumbroso/free-disk-space@main
    #   uses: jayllyz/free-disk-space@perf/use-rmz
    #   with:
    #     tool-cache: true
    #     android: true
    #     dotnet: true
    #     haskell: true
    #     large-packages: true
    #     docker-images: false
    #     swap-storage: true

    - name: Install dependencies on host
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          lbzip2 \
          ntpdate \
          libncurses5-dev \
          libncursesw5-dev \
          libxml2-utils \
          qemu-user-static \
          xmlstarlet

    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up QEMU for ARM64 emulation
      run: |
        sudo update-binfmts --enable qemu-aarch64
        docker run --rm --privileged multiarch/qemu-user-static --reset -p yes

    - name: Restore Cached L4T BSP
      id: cache-bsp
      uses: actions/cache@v4
      with:
        path: ${{ github.workspace }}/Linux_for_Tegra.tar.zst
        key: bsp-${{ env.L4T_MAJOR_VERSION }}.${{ env.L4T_MINOR_VERSION }}
        fail-on-cache-miss: true

    - name: Extract L4T packages
      run: |
        cd $GITHUB_WORKSPACE
        echo "Extracting L4T Driver Package..."
        sudo tar --extract --same-permissions --use-compress-program=zstd -f ${{ github.workspace }}/Linux_for_Tegra.tar.zst
        echo "Remove cache file..."
        rm ${{ github.workspace }}/Linux_for_Tegra.tar.zst

    - name: Patch files
      run: |
        #Update base image
        sed -i 's|ubuntu-base-22.04.2-base-arm64.tar.gz|ubuntu-base-22.04.5-base-arm64.tar.gz|g' ${{ github.workspace }}/Linux_for_Tegra/tools/samplefs/nvubuntu-jammy-aarch64-samplefs
        # Move rootFS Folder instead of creating tarball
        sed -i 's|sudo tar --numeric-owner -jcpf "${output_samplefs}" \*|sudo mv ./* '"${{ github.workspace }}"'/Linux_for_Tegra/rootfs|' ./Linux_for_Tegra/tools/samplefs/nv_build_samplefs.sh

    - name: Copy files
      run: |
        #Copy package list for RootFS
        cp samplefs/nvubuntu-jammy-nano-aarch64-packages ${{ github.workspace }}/Linux_for_Tegra/tools/samplefs/nvubuntu-jammy-nano-aarch64-packages


    - name: Create Ubuntu RootFS
      run: |
        sudo rm -rf ${{ github.workspace }}/Linux_for_Tegra/rootfs/*
        sudo ${{ github.workspace }}/Linux_for_Tegra/tools/samplefs/nv_build_samplefs.sh --abi aarch64 --distro ubuntu --flavor nano --version jammy

    - name: remove packages we don't want to install
      run: |
        cd $GITHUB_WORKSPACE/Linux_for_Tegra/nv_tegra/l4t_deb_packages
        sudo rm -f nvidia-igx-oem-config*.deb \
          nvidia-l4t-libwayland-egl1*.deb \
          nvidia-igx-systemd-reboot-hooks*.deb \
          nvidia-l4t-libwayland-server0*.deb \
          nvidia-l4t-camera*.deb \
          nvidia-l4t-dgpu-x11*.deb \
          nvidia-l4t-jetsonpower-gui-tools*.deb \
          nvidia-l4t-libwayland-client0*.deb \
          nvidia-l4t-dgpu-tools*.deb \
          nvidia-l4t-dgpu-config*.deb \
          nvidia-l4t-dgpu-apt-source*.deb \
          nvidia-l4t-graphics-demos*.deb \
          nvidia-l4t-libwayland-cursor0*.deb \
          nvidia-l4t-vulkan-sc-sdk*.deb \
          nvidia-l4t-wayland*.deb \
          nvidia-l4t-vulkan-sc-dev*.deb \
          nvidia-l4t-vulkan-sc-samples*.deb \
          nvidia-l4t-vulkan-sc*.deb \
          nvidia-l4t-pva*.deb \
          nvidia-l4t-factory-service*.deb \
          nvidia-l4t-x11*.deb \
          nvidia-l4t-3d-core*.deb \
          nvidia-l4t-openwfd*.deb \
          nvidia-l4t-gbm*.deb \
          nvidia-l4t-jetson-io*.deb \
          nvidia-l4t-weston*.deb \
          nvidia-l4t-multimedia*.deb \
          nvidia-l4t-multimedia-utils*.deb \
          nvidia-l4t-nvpmodel-gui-tools*.deb

    - name: Add docker packages to rootfs
      run: |
        set -eux
        cd "$GITHUB_WORKSPACE/Linux_for_Tegra"

        CHROOT="$(pwd)/rootfs"

        # copy qemu-user static for aarch64 chroot execution
        echo "Setting up chroot environment..."
        sudo mkdir -p "$CHROOT/usr/bin"
        sudo cp /usr/bin/qemu-aarch64-static "$CHROOT/usr/bin/" || true

        # Mount pseudo filesystems for chroot
        for m in proc sys dev dev/pts run; do
          sudo mkdir -p "$CHROOT/$m"
          sudo mount --bind "/$m" "$CHROOT/$m" || true
        done

        # Backup and copy resolv.conf (if present)
        if [ -L "$CHROOT/etc/resolv.conf" ]; then
          sudo mv "$CHROOT/etc/resolv.conf" "$CHROOT/etc/resolv.conf.bak" || true
        fi
        sudo cp /etc/resolv.conf "$CHROOT/etc/resolv.conf" || true

        # seed fake-hwclock in chroot (assumes package already installed in chroot)
        sudo chroot $CHROOT /bin/bash -ex <<'CH'
          # seed with builder time
          DEBIAN_FRONTEND=noninteractive fake-hwclock save || true
        CH

        # If the package-provided fake-hwclock systemd unit exists, enable it in the image
        if [ -f "$CHROOT/lib/systemd/system/fake-hwclock.service" ] || [ -f "$CHROOT/usr/lib/systemd/system/fake-hwclock.service" ]; then
          sudo mkdir -p "$CHROOT/etc/systemd/system/sysinit.target.wants"
          if [ -f "$CHROOT/lib/systemd/system/fake-hwclock.service" ]; then
            sudo ln -sf /lib/systemd/system/fake-hwclock.service "$CHROOT/etc/systemd/system/sysinit.target.wants/fake-hwclock.service"
          else
            sudo ln -sf /usr/lib/systemd/system/fake-hwclock.service "$CHROOT/etc/systemd/system/sysinit.target.wants/fake-hwclock.service"
          fi
        fi

        # Check fake-hwclock file exists and looks sane (YYYY-MM-DD HH:MM:SS)
        if [ -f "$CHROOT/etc/fake-hwclock.data" ]; then
          echo "/etc/fake-hwclock.data:"
          sudo cat "$CHROOT/etc/fake-hwclock.data"
        else
          echo "WARNING: /etc/fake-hwclock.data not found"
        fi
        # Quick check: run 'date' inside chroot (will show host time)
        sudo chroot "$CHROOT" date -u -R

        # Add apt keyrings / repos for docker & nvidia
        sudo mkdir -p "$CHROOT/usr/bin" "$CHROOT/etc/apt/keyrings"
        sudo install -m 0755 -d $CHROOT/etc/apt/keyrings
        sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o $CHROOT/etc/apt/keyrings/docker.asc
        sudo curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey -o $CHROOT/etc/apt/keyrings/nvidia-container-toolkit.asc
        sudo chmod a+r $CHROOT/etc/apt/keyrings/docker.asc
        sudo chmod a+r $CHROOT/etc/apt/keyrings/nvidia-container-toolkit.asc
        echo \
          "deb [arch=arm64 signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu jammy stable" | \
          sudo tee $CHROOT/etc/apt/sources.list.d/docker.list > /dev/null
        echo \
          "deb [signed-by=/etc/apt/keyrings/nvidia-container-toolkit.asc] https://nvidia.github.io/libnvidia-container/stable/deb/arm64 /" | \
          sudo tee $CHROOT/etc/apt/sources.list.d/nvidia-container-toolkit.list > /dev/null

        # Install docker packages inside the chroot
        pushd "$CHROOT"
        echo "/etc/resolv.conf"
        cat /etc/resolv.conf
        echo "apt get update"
        LC_ALL=C PYTHONHASHSEED=0 sudo chroot . apt-get update
        LC_ALL=C PYTHONHASHSEED=0 sudo chroot . apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin nvidia-container-toolkit
        LC_ALL=C PYTHONHASHSEED=0 sudo chroot . pip3 install -U "setuptools<71.0.0"
        LC_ALL=C PYTHONHASHSEED=0 sudo chroot . sudo pip3 install -U jetson-stats || true
        popd
        echo "Docker package installation completed!"

        # restore resolv.conf and cleanup
        sudo rm -f "$CHROOT/etc/resolv.conf"
        if [ -L "$CHROOT/etc/resolv.conf.bak" ]; then
          sudo mv "$CHROOT/etc/resolv.conf.bak" "$CHROOT/etc/resolv.conf" || true
        fi

        # Unmount filesystems (use lazy unmount to avoid hung mounts)
        echo "Unmount filesystems..."
        for m in run dev/pts dev sys proc; do
          sudo umount -l "$CHROOT/$m" || true
        done

        # Remove QEMU binary from rootfs (after unmount)
        echo "Removing QEMU binary from rootfs..."
        sudo rm -f "$CHROOT/usr/bin/qemu-aarch64-static" || true

    - name: Add docker default runtime
      run: |
        cat <<EOF | sudo tee $GITHUB_WORKSPACE/Linux_for_Tegra/rootfs/etc/docker/daemon.json >/dev/null
          {
            "runtimes": {
              "nvidia": {
                "path": "nvidia-container-runtime",
                "runtimeArgs": []
              }
            },
            "default-runtime": "nvidia"
          }
        EOF

    - name: Apply NVIDIA proprietary binaries
      run: |
        echo "Applying NVIDIA L4T binaries..."
        sudo $GITHUB_WORKSPACE/Linux_for_Tegra/apply_binaries.sh
        sudo sed -i 's|<SOC>|t234|g' $GITHUB_WORKSPACE/Linux_for_Tegra/rootfs/etc/apt/sources.list.d/nvidia-l4t-apt-source.list

        # Verify the script completed successfully
        if [ $? -eq 0 ]; then
          echo "✅ NVIDIA binaries applied successfully"
        else
          echo "❌ Failed to apply NVIDIA binaries"
          exit 1
        fi

    - name: Create default user
      run: |
        echo "Creating etc/nv folder..."
        sudo mkdir -p $GITHUB_WORKSPACE/Linux_for_Tegra/rootfs/etc/nv
        echo "Remove readme from rootfs..."
        sudo rm -f $GITHUB_WORKSPACE/Linux_for_Tegra/rootfs/README.txt
        echo "Creating default user..."
        sudo $GITHUB_WORKSPACE/Linux_for_Tegra/tools/l4t_create_default_user.sh \
          -u ${{ env.OEM_USER }} \
          -p jetson \
          -n nexus1-basestation \
          --accept-license

    - name: Copy user creation script
      run: |
        cp $GITHUB_WORKSPACE/Linux_for_Tegra/tools/l4t_create_default_user.sh $GITHUB_WORKSPACE/l4t_create_default_user.sh

    # - name: Copy custom files to rootfs
    #   run: |
    #     cd $GITHUB_WORKSPACE/Linux_for_Tegra

    #     # Copy any custom files from repository to rootfs
    #     if [ -d "${{ github.workspace }}/rootfs-overlay" ]; then
    #       echo "Copying custom files from rootfs-overlay..."
    #       sudo cp -r ${{ github.workspace }}/rootfs-overlay/* rootfs/
    #     fi

    #     # sudo chmod +x rootfs/opt/custom/custom_startup.sh

    #     # sudo chroot rootfs systemctl enable jetson-custom-init.service

    - name: Patch jetson-disk-image-creator.sh for NVME support
      run: |
        sed -i '/"USB" | "usb")/,/\*/c\
        			"USB" | "usb")\
        				rootfs_dev="sda1"\
        				;;\
        			"NVME" | "nvme")\
        				rootfs_dev="nvme0n1p1"\
        				;;\
        			*)' $GITHUB_WORKSPACE/Linux_for_Tegra/tools/jetson-disk-image-creator.sh

        sed -i 's/Incorrect root filesystem device - Supported devices - SD, USB/\
            Incorrect root filesystem device - Supported devices - SD, USB, NVME/g' $GITHUB_WORKSPACE/Linux_for_Tegra/tools/jetson-disk-image-creator.sh

    - name: Generate ${{ env.IMAGE_TYPE }} image
      run: |
        cd $GITHUB_WORKSPACE/Linux_for_Tegra

        # Determine image name
        IMAGE_NAME="${{ env.JETSON_TYPE }}"
        TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
        # FULL_IMAGE_NAME="${IMAGE_NAME}_${TIMESTAMP}_${{ env.IMAGE_TYPE }}.img"
        FULL_IMAGE_NAME="${IMAGE_NAME}.img"

        echo "Creating ${{ env.IMAGE_TYPE }} image: $FULL_IMAGE_NAME"

        # Create the ${{ env.IMAGE_TYPE }} image
        cd tools
        sudo ./jetson-disk-image-creator.sh \
          -o "$FULL_IMAGE_NAME" \
          -b ${{ env.JETSON_TYPE }} \
          -d ${{ env.IMAGE_TYPE }}

        # Move image to workspace root for artifact upload
        sudo mv "$FULL_IMAGE_NAME" $GITHUB_WORKSPACE/

        # Create checksum
        cd $GITHUB_WORKSPACE
        sha256sum "$FULL_IMAGE_NAME" > "$FULL_IMAGE_NAME.sha256"

        # Create image info file
        cat > "$FULL_IMAGE_NAME.info" << EOF
        Jetson Custom ${{ env.IMAGE_TYPE }} Image
        =====================================

        Build Information:
        - Build Date: $(date -u)
        - L4T Version: ${{ env.L4T_MAJOR_VERSION }}.${{ env.L4T_MINOR_VERSION }}
        - GitHub SHA: ${{ github.sha }}
        - GitHub Ref: ${{ github.ref }}
        - Workflow: ${{ github.workflow }}
        - Runner OS: ${{ runner.os }}

        Image Details:
        - Filename: $FULL_IMAGE_NAME
        - Target Device: ${{ env.JETSON_TYPE }}
        - Root Filesystem: Ubuntu 22.04 LTS (ARM64)
        - Default User: ${{ env.OEM_USER }} / jetson

        Custom Packages Included:
        # - Development tools (git, vim, htop, build-essential, cmake)
        - Docker
        - Network management tools

        Usage Instructions:
        1. Flash to ${{ env.IMAGE_TYPE }} using Raspberry Pi Imager or dd command
        2. Insert into ${{ env.JETSON_TYPE }}
        3. Power on and complete initial setup
        4. Default login: ${{ env.OEM_USER }} / jetson (change on first login)

        For support and documentation:
        https://github.com/${{ github.repository }}
        EOF

        echo "IMAGE_NAME=$FULL_IMAGE_NAME" >> $GITHUB_ENV

    - name: Compress image for faster upload
      run: |
        cd $GITHUB_WORKSPACE
        echo "Compressing image for upload..."

        # Compress with pigz
        pigz -6 -p $(nproc) "${IMAGE_NAME}"

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: jetson-orin-nano-image-${{ github.run_number }}
        path: |
          ${{ env.IMAGE_NAME }}.gz
          ${{ env.IMAGE_NAME }}.sha256
          ${{ env.IMAGE_NAME }}.info
        retention-days: 30

    - name: Upload Image as Release Asset
      if: startsWith(github.ref, 'refs/tags/')
      uses: softprops/action-gh-release@v2
      with:
        files: |
          ${{ env.IMAGE_NAME }}.gz
          ${{ env.IMAGE_NAME }}.sha256
          ${{ env.IMAGE_NAME }}.info
        body: |
          ## Jetson ${{ env.IMAGE_TYPE }} Image

          This release contains a custom ${{ env.IMAGE_TYPE }} image for the NVIDIA ${{ env.JETSON_TYPE }}.

          ### What's Included
          - L4T Version: ${{ env.L4T_MAJOR_VERSION }}.${{ env.L4T_MINOR_VERSION }}
          - Ubuntu 22.04 LTS ARM64
          - Custom development packages
          - Docker pre-installed
          - Default user: ${{ env.OEM_USER }}/jetson

          ### Installation
          1. Download the `.img.gz` file
          2. Extract using: `xz -d filename.img.gz`
          3. Flash to ${{ env.IMAGE_TYPE }} using Raspberry Pi Imager or dd
          4. insert memory into your Jetson
          5. Boot your ${{ env.JETSON_TYPE }}

          ### Files
          - `*.img.gz` - Compressed ${{ env.IMAGE_TYPE }} image
          - `*.sha256` - Checksum for verification
          - `*.info` - Build and usage information

        draft: false
        prerelease: false
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    # - name: Upload All Split Files as Release Assets
    #   if: startsWith(github.ref, 'refs/tags/')
    #   env:
    #     GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    #     TAG_NAME: ${{ github.ref_name }}
    #     REPO: ${{ github.repository }}
    #   run: |
    #     for i in $(seq -w 00 99); do
    #       FILE="${{ env.IMAGE_NAME }}.gz.${i}"
    #       if [ -f "$FILE" ]; then
    #         echo "Uploading $FILE..."
    #         gh release upload "$TAG_NAME" "$FILE" --repo "$REPO" --clobber
    #       else
    #         echo "Skipping missing file: $FILE"
    #       fi
    #     done

    # - name: Cleanup workspace
    #   if: always()
    #   run: |
    #     cd /
    #     sudo rm -rf $GITHUB_WORKSPACE || true

  publish-release:
    needs: [create-draft, build-jetson-image]
    runs-on: ubuntu-latest
    steps:
      - name: Publish draft as release
        if: startsWith(github.ref, 'refs/tags/')
        uses: eregon/publish-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          release_id: ${{ needs.create-draft.outputs.release_id }}
